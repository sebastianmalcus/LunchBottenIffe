import asyncio
import requests
import os
from bs4 import BeautifulSoup
from datetime import datetime
from telegram import Bot

TOKEN = os.getenv('TELEGRAM_TOKEN')
CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')

def get_day_number():
    return datetime.now().weekday() + 1

def scrape_nya_etage():
    try:
        url = "https://nyaetage.se/"
        res = requests.get(url, timeout=15, headers={'User-Agent': 'Mozilla/5.0'})
        res.encoding = 'utf-8' 
        soup = BeautifulSoup(res.text, 'html.parser')
        
        day_num = get_day_number()
        day_card = soup.find('div', attrs={'data-day': str(day_num)})
        
        if not day_card:
            return "‚ö†Ô∏è Hittade inte dagens meny-kort."

        items_container = day_card.find('div', class_='menu-items')
        if not items_container:
            return "‚ö†Ô∏è Hittade inte r√§tterna i boxen."

        dagens = []
        veggo = ""
        
        for text in items_container.stripped_strings:
            text = text.lstrip('>').lstrip('‚Ä¢').strip().replace('*', '').replace('_', '')
            if len(text) > 5 and text.lower() != "idag":
                if "veg/" in text.lower() or "vegan" in text.lower():
                    if text not in veggo:
                        veggo = f"\nü•ó *Vegetariskt*\n‚Ä¢ {text}"
                else:
                    if f"‚Ä¢ {text}" not in dagens:
                        dagens.append(f"‚Ä¢ {text}")

        meny = "\n".join(dagens)
        if veggo:
            meny += veggo
            
        return meny if meny else "‚ö†Ô∏è Inga r√§tter hittades."
    except Exception as e:
        return f"‚ùå Fel vid skrapning: {str(e)}"

def scrape_sodra_porten():
    try:
        target_url = "https://sodraporten.kvartersmenyn.se/"
        html_content = ""
        
        # F√∂rs√∂k 1: Direkt anrop med ordentlig f√∂rkl√§dnad
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/122.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'sv,en-US;q=0.7,en;q=0.3'
        }
        
        res = requests.get(target_url, timeout=10, headers=headers)
        if res.status_code == 200:
            res.encoding = 'utf-8'
            html_content = res.text
        else:
            # F√∂rs√∂k 2: Anv√§nd CodeTabs som en ny, starkare tunnel
            proxy_url = f"https://api.codetabs.com/v1/proxy?quest={target_url}"
            res_proxy = requests.get(proxy_url, timeout=20)
            
            if res_proxy.status_code == 200:
                html_content = res_proxy.text
            else:
                return f"‚ö†Ô∏è B√•de direktl√§nk (Fel {res.status_code}) och tunnel (Fel {res_proxy.status_code}) blockerades."

        soup = BeautifulSoup(html_content, 'html.parser')
        
        days = ["M√•ndag", "Tisdag", "Onsdag", "Torsdag", "Fredag"]
        today_str = days[datetime.now().weekday()].lower()
        
        # 1. Hitta menyl√•dan
        menu_div = soup.find('div', class_='meny') or soup.find('div', class_='menu_perc_div')
        
        if not menu_div:
            # Reservplan
            day_tag = soup.find(lambda t: t.name in ['strong', 'b', 'h3', 'h4'] and today_str.lower() in t.get_text().lower())
            if day_tag:
                menu_div = day_tag.parent
                
        if not menu_div:
            return "‚ö†Ô∏è Hittade inte meny-containern p√• sidan."

        # 2. Platta till <br>-taggarna till riktiga radbrytningar
        for br in menu_div.find_all('br'):
            br.replace_with('\n')
            
        text_content = menu_div.get_text(separator='\n')
        lines = [line.strip() for line in text_content.split('\n') if line.strip()]
        
        menu_items = []
        capture = False
        ignore_words = ["gr√∂nt", "dagens", "sallad", "action", "fresh", "betala", "pris", "inkl", "√∂ppet", "***", "husmanskost", "pogre"]
        
        # 3. Filtrera raderna
        for line in lines:
            lower_line = line.lower()
            
            is_day = False
            for d in days:
                if lower_line == d.lower() or lower_line.startswith(d.lower() + ":"):
                    is_day = True
                    if d.lower() == today_str.lower():
                        capture = True
                    else:
                        capture = False
                    break
                    
            if is_day:
                continue
                
            if capture:
                if "inkl" in lower_line or "√∂ppet" in lower_line or "pris fr" in lower_line:
                    break
                    
                if len(line) > 8:
                    if not any(lower_line.startswith(iw) for iw in ignore_words) and lower_line not in ignore_words:
                        clean_line = line.replace('*', '').replace('_', '').replace('"', '').strip()
                        if f"‚Ä¢ {clean_line}" not in menu_items:
                            menu_items.append(f"‚Ä¢ {clean_line}")
                            
        return "\n".join(menu_items) if menu_items else "‚ö†Ô∏è Koden l√§ste rutan men hittade inga r√§tter."
    except Exception as e:
        return f"‚ùå Fel: {str(e)}"

async def main():
    if datetime.now().weekday() >= 5: 
        return 
    
    bot = Bot(token=TOKEN)
    etage = scrape_nya_etage()
    sodra = scrape_sodra_porten()
    
    dag = ["M√ÖNDAG", "TISDAG", "ONSDAG", "TORSDAG", "FREDAG"][datetime.now().weekday()]
    
    msg = (
        f"üç¥ *LUNCH {dag}* üç¥\n\n"
        f"üìç *Nya Etage*\n{etage}\n\n"
        f"üìç *S√∂dra Porten*\n{sodra}\n\n"
        "Smaklig m√•ltid!"
    )
    
    await bot.send_message(chat_id=CHAT_ID, text=msg, parse_mode='Markdown')

if __name__ == "__main__":
    asyncio.run(main())
